{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import Error\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_json(data, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "def read_from_json(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to PostgreSQL\n"
     ]
    }
   ],
   "source": [
    "# Connection string\n",
    "conn_string = os.getenv('DATABASE_URL')\n",
    "\n",
    "try:\n",
    "    # Connect to PostgreSQL database\n",
    "    connection = psycopg2.connect(conn_string)\n",
    "    print(\"Connected to PostgreSQL\")\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "except (Exception, Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL:\", error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'data' already exists.\n"
     ]
    }
   ],
   "source": [
    "def create_folder(folder_name):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "        print(f\"Folder '{folder_name}' created.\")\n",
    "    else:\n",
    "        print(f\"Folder '{folder_name}' already exists.\")\n",
    "\n",
    "# Example usage:\n",
    "folder_name = \"data\"\n",
    "create_folder(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inserting Organization Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "organization_data_list = [\n",
    "    {\n",
    "        \"name\": \"Example Organization 1\",\n",
    "        \"contact_email\": \"example1@example.com\",\n",
    "        \"phone_number\": \"+1234567890\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Example Organization 2\",\n",
    "        \"contact_email\": \"example2@example.com\",\n",
    "        \"phone_number\": \"+9876543210\"\n",
    "    },\n",
    "    # Add more organization data dictionaries as needed\n",
    "]\n",
    "\n",
    "# Write organization data to JSON file\n",
    "write_to_json(organization_data_list, f\"{folder_name}/organization_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organization 'Tech Innovations Inc.' inserted with ID: 8fd51c1d-32f9-48e3-a473-cf57f29bea05\n"
     ]
    }
   ],
   "source": [
    "connection = psycopg2.connect(conn_string)\n",
    "cursor = connection.cursor()\n",
    "try:\n",
    "\n",
    "    # Read organization data from JSON file\n",
    "    organization_data_list = read_from_json(f\"{folder_name}/organization_data.json\")\n",
    "\n",
    "    # Define the INSERT query\n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO \"Organization\" (name, contact_email, phone_number)\n",
    "        VALUES (%s, %s, %s)\n",
    "        RETURNING id\n",
    "    \"\"\"\n",
    "\n",
    "    # Iterate over organization data list and insert each entry\n",
    "    for organization_data in organization_data_list:\n",
    "        # Execute the INSERT query\n",
    "        cursor.execute(insert_query, (organization_data[\"name\"], organization_data[\"contact_email\"], organization_data[\"phone_number\"]))\n",
    "        organization_id = cursor.fetchone()[0]  # Get the ID of the inserted organization\n",
    "        print(f\"Organization '{organization_data['name']}' inserted with ID: {organization_id}\")\n",
    "\n",
    "    # Commit the transaction\n",
    "    connection.commit()\n",
    "except (Exception, Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL:\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organization 'Tech Innovations Inc.' inserted with ID: 8fd51c1d-32f9-48e3-a473-cf57f29bea05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inserting Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Organization ID to be used for Location\n",
    "org_id = '8fd51c1d-32f9-48e3-a473-cf57f29bea05'\n",
    "number_of_locations = 20\n",
    "\n",
    "# Generate fake location data and write to JSON file\n",
    "def generate_location_data(org_id, number_of_locations):\n",
    "    locations = []\n",
    "    for _ in range(number_of_locations):\n",
    "        location = {\n",
    "            \"org_id\": org_id,\n",
    "            \"name\": fake.street_name(),\n",
    "            \"description\": fake.text(max_nb_chars=200) if fake.boolean(chance_of_getting_true=50) else None,\n",
    "            \"latitude\": float(fake.latitude()),\n",
    "            \"longitude\": float(fake.longitude())\n",
    "        }\n",
    "        locations.append(location)\n",
    "    \n",
    "    write_to_json(locations,f\"{folder_name}/locations.json\")\n",
    "\n",
    "# Generate and write fake location data to JSON\n",
    "generate_location_data(org_id, number_of_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 20 fake Location entries into the database.\n"
     ]
    }
   ],
   "source": [
    "# Now read the data from the JSON file and insert it into the database\n",
    "def insert_locations_from_json(cursor, json_file):\n",
    "    locations = read_from_json(f\"{folder_name}/locations.json\")\n",
    "\n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO \"Location\" ( org_id, name, description, latitude, longitude)\n",
    "        VALUES (%s, %s, %s, %s, %s);\n",
    "    \"\"\"\n",
    "\n",
    "    for location in locations:\n",
    "        cursor.execute(insert_query, (\n",
    "            location['org_id'],\n",
    "            location['name'],\n",
    "            location['description'],\n",
    "            location['latitude'],\n",
    "            location['longitude']\n",
    "        ))\n",
    "\n",
    "# Set up database connection\n",
    "connection_string = os.getenv('DATABASE_URL')\n",
    "conn = psycopg2.connect(connection_string)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Read from the JSON file and insert data into PostgreSQL\n",
    "insert_locations_from_json(cursor, 'locations.json')\n",
    "\n",
    "# Commit the transaction\n",
    "conn.commit()\n",
    "\n",
    "# Clean up\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"Inserted {number_of_locations} fake Location entries into the database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to be done for uuid\n",
    "ALTER TABLE \"Location\" ALTER COLUMN id SET DEFAULT uuid_generate_v4();\n",
    "CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organization 'Tech Innovations Inc.' inserted with ID: 8fd51c1d-32f9-48e3-a473-cf57f29bea05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Inserting Skill Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data written to data/skill_categories.json\n"
     ]
    }
   ],
   "source": [
    "from faker import Faker\n",
    "import json\n",
    "\n",
    "# Create a Faker instance\n",
    "faker = Faker()\n",
    "\n",
    "# Define the static organization ID\n",
    "org_id = '8fd51c1d-32f9-48e3-a473-cf57f29bea05'\n",
    "\n",
    "# Skill category names and descriptions\n",
    "skill_categories_info = [\n",
    "    (\"Senior Management\", \"Skills relevant to leadership and high-level management decisions.\"),\n",
    "    (\"Cybersecurity\", \"Skills related to protecting information from unauthorized access and cyber threats.\"),\n",
    "    (\"Software Engineering\", \"Skills in designing, developing, testing, and evaluating software systems.\"),\n",
    "    (\"Project Management\", \"Skills required for effectively managing projects and resources.\"),\n",
    "    (\"Data Science\", \"Skills for analyzing complex data to extract actionable insights.\"),\n",
    "    (\"DevOps\", \"Skills for collaboration between software development and IT operations.\"),\n",
    "    (\"Cloud Computing\", \"Skills related to the delivery of computing services over the internet.\"),\n",
    "    (\"Front End Technologies\", \"Skills in client-side development, such as using Angular, React JS, and Vue.\"),\n",
    "    (\"Server Side Technologies\", \"Skills in server-side development, such as Node JS, Java Spring Boot, .NET, Laravel, Adobe Cold fusion.\"),\n",
    "    (\"Database Technologies\", \"Skills related to database management, such as SQL.\"),\n",
    "    (\"Business Intelligence\", \"Skills in BI tools like Apache Superset, Power BI, Tableau, Looker.\"),\n",
    "    (\"User Interface Design\", \"Skills in UI design and development, such as Wordpress, Web Designing (HTML, CSS, SCSS), Javascript (ES6).\"),\n",
    "    (\"Mobile Development\", \"Skills in mobile app development, such as Flutter and React Native.\"),\n",
    "    (\"Web Scraping\", \"Skills in scraping technologies like Selenium / Puppeteer.\"),\n",
    "    (\"Scripting Languages\", \"Skills in scripting languages, such as Python.\"),\n",
    "    (\"ELT / ETL Technologies\", \"Skills in ELT/ETL processes, such as DBT, Alteryx, Azure Synapse, Databricks (Spark), Matillion.\"),\n",
    "    (\"Data Warehousing\", \"Skills related to data warehousing, such as Snowflake.\"),\n",
    "    (\"Machine Learning\", \"Skills in ML technologies like opencv, scikit-learn, tensorflow, neural networks.\"),\n",
    "    (\"Natural Language Processing\", \"Skills in NLP and sentimental analysis.\"),\n",
    "    (\"Cloud Operations\", \"Skills in cloud operations, including Cloud Native (Containerization & Orchestration), Azure Logic Apps, Microsoft Flow, Serverless.\")\n",
    "]\n",
    "\n",
    "# Generate SkillCategory entries with Faker-generated IDs\n",
    "skill_categories = [\n",
    "    {\n",
    "        \"id\": faker.uuid4(),\n",
    "        \"org_id\": org_id,\n",
    "        \"name\": name,\n",
    "        \"description\": description\n",
    "    }\n",
    "    for name, description in skill_categories_info\n",
    "]\n",
    "\n",
    "# Define the folder name where the file will be saved\n",
    "\n",
    "# Write the JSON string to a file\n",
    "json_filename = f'{folder_name}/skill_categories.json'\n",
    "\n",
    "# Write the JSON data to a file\n",
    "with open(json_filename, 'w') as file:\n",
    "    json.dump(skill_categories, file, indent=2)\n",
    "\n",
    "print(f\"JSON data written to {json_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 13 SkillCategory entries into the database.\n"
     ]
    }
   ],
   "source": [
    "# Function to read data from a JSON file\n",
    "def read_from_json(json_file_path):\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Now read the data from the JSON file and insert it into the database\n",
    "def insert_skill_categories_from_json(cursor, json_data):\n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO \"SkillCategory\" (id, org_id, name, description)\n",
    "        VALUES (%s, %s, %s, %s);\n",
    "    \"\"\"\n",
    "\n",
    "    for skill_category in json_data:\n",
    "        cursor.execute(insert_query, (\n",
    "            skill_category['id'],\n",
    "            skill_category['org_id'],\n",
    "            skill_category['name'],\n",
    "            skill_category['description']\n",
    "        ))\n",
    "\n",
    "# Function to connect to the database and insert data\n",
    "# Read from the JSON file\n",
    "skill_categories_json_path = f'{folder_name}/skill_categories.json'\n",
    "skill_categories = read_from_json(skill_categories_json_path)\n",
    "\n",
    "# Set up database connection using environment variables\n",
    "connection_string = os.getenv('DATABASE_URL')\n",
    "conn = psycopg2.connect(connection_string)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Insert data into PostgreSQL\n",
    "insert_skill_categories_from_json(cursor, skill_categories)\n",
    "\n",
    "# Commit the transaction\n",
    "conn.commit()\n",
    "\n",
    "# Clean up\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"Inserted {len(skill_categories)} SkillCategory entries into the database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Inserting Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/skills.json'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming the skill categories JSON is stored in 'skill_categories.json'\n",
    "skill_categories_file = f'{folder_name}/skill_categories.json'\n",
    "\n",
    "\n",
    "# Load the skill categories from the JSON file to get the real UUIDs\n",
    "with open(skill_categories_file, 'r') as file:\n",
    "    skill_categories_data = json.load(file)\n",
    "    category_id_map = {category['name']: category['id'] for category in skill_categories_data}\n",
    "\n",
    "# Extended list of skills for each category with at least four skills per category\n",
    "skills_info = [\n",
    "    # Senior Management\n",
    "    (\"Corporate governance\", \"Understanding and applying the best practices for corporate governance.\", category_id_map[\"Senior Management\"]),\n",
    "    (\"Strategic planning\", \"Developing long-term strategies for the organization's growth.\", category_id_map[\"Senior Management\"]),\n",
    "    (\"Visionary leadership\", \"Providing direction and inspiring the organization to achieve its vision.\", category_id_map[\"Senior Management\"]),\n",
    "    (\"Financial acumen\", \"Understanding and applying financial principles to drive business success.\", category_id_map[\"Senior Management\"]),\n",
    "\n",
    "    # Cybersecurity\n",
    "    (\"Network security\", \"Protecting computer networks from intrusions and attacks.\", category_id_map[\"Cybersecurity\"]),\n",
    "    (\"Information security\", \"Ensuring the confidentiality, integrity, and availability of data.\", category_id_map[\"Cybersecurity\"]),\n",
    "    (\"Cybersecurity policies\", \"Developing and enforcing policies to protect against cyber threats.\", category_id_map[\"Cybersecurity\"]),\n",
    "    (\"Incident response\", \"Responding to and recovering from security breaches and incidents.\", category_id_map[\"Cybersecurity\"]),\n",
    "\n",
    "    # Software Engineering\n",
    "    (\"System design\", \"Architecting complex software systems to meet business requirements.\", category_id_map[\"Software Engineering\"]),\n",
    "    (\"Coding best practices\", \"Maintaining high standards of coding and software development.\", category_id_map[\"Software Engineering\"]),\n",
    "    (\"Software testing\", \"Designing and executing tests to ensure software quality.\", category_id_map[\"Software Engineering\"]),\n",
    "    (\"Continuous integration\", \"Automating the integration of code changes from multiple contributors.\", category_id_map[\"Software Engineering\"]),\n",
    "\n",
    "    # Project Management\n",
    "    (\"Resource allocation\", \"Effectively distributing resources across projects to ensure efficient use.\", category_id_map[\"Project Management\"]),\n",
    "    (\"Risk assessment\", \"Identifying potential risks in project planning and execution.\", category_id_map[\"Project Management\"]),\n",
    "    (\"Project scheduling\", \"Planning and organizing project tasks and timelines.\", category_id_map[\"Project Management\"]),\n",
    "    (\"Stakeholder management\", \"Managing relationships with all project stakeholders.\", category_id_map[\"Project Management\"]),\n",
    "\n",
    "    # Data Science\n",
    "    (\"Data Analysis\", \"Analyzing and interpreting complex datasets to extract meaningful insights.\", category_id_map[\"Data Science\"]),\n",
    "    (\"Machine Learning\", \"Applying statistical models and algorithms to data to predict outcomes.\", category_id_map[\"Data Science\"]),\n",
    "    (\"Data visualization\", \"Representing data in graphical format to aid understanding.\", category_id_map[\"Data Science\"]),\n",
    "    (\"Big Data technologies\", \"Utilizing technologies for processing large datasets.\", category_id_map[\"Data Science\"]),\n",
    "\n",
    "    # DevOps\n",
    "    (\"Continuous Integration/Continuous Deployment\", \"Implementing CI/CD pipelines for software delivery.\", category_id_map[\"DevOps\"]),\n",
    "    (\"Automation scripting\", \"Writing scripts to automate operational processes.\", category_id_map[\"DevOps\"]),\n",
    "    (\"Infrastructure as Code\", \"Managing infrastructure through code to improve deployment speed.\", category_id_map[\"DevOps\"]),\n",
    "    (\"Monitoring and logging\", \"Tracking and analyzing system performance and activity.\", category_id_map[\"DevOps\"]),\n",
    "\n",
    "    # Cloud Computing\n",
    "    (\"Cloud Service Management\", \"Managing cloud services and infrastructure.\", category_id_map[\"Cloud Computing\"]),\n",
    "    (\"Cloud Migration Strategies\", \"Planning and executing the migration of services to cloud environments.\", category_id_map[\"Cloud Computing\"]),\n",
    "    (\"Cloud Security\", \"Ensuring the security of cloud-based applications and data.\", category_id_map[\"Cloud Computing\"]),\n",
    "    (\"Cloud resource optimization\", \"Managing cloud resources to optimize performance and cost.\", category_id_map[\"Cloud Computing\"]),\n",
    "\n",
    "    # Front End Technologies\n",
    "    (\"Angular\", \"Angular development.\", category_id_map[\"Front End Technologies\"]),\n",
    "    (\"React\", \"React development.\", category_id_map[\"Front End Technologies\"]),\n",
    "    (\"Vue\", \"Vue.js development.\", category_id_map[\"Front End Technologies\"]),\n",
    "    (\"HTML/CSS\", \"Web development using HTML and CSS.\", category_id_map[\"Front End Technologies\"]),\n",
    "\n",
    "    # Server Side Technologies\n",
    "    (\"Node.js\", \"Backend development with Node.js.\", category_id_map[\"Server Side Technologies\"]),\n",
    "    (\"Spring Boot\", \"Application development with Java Spring Boot.\", category_id_map[\"Server Side Technologies\"]),\n",
    "    (\".NET\", \".NET framework development.\", category_id_map[\"Server Side Technologies\"]),\n",
    "    (\"Laravel\", \"Web development with Laravel.\", category_id_map[\"Server Side Technologies\"]),\n",
    "\n",
    "    # Database Technologies\n",
    "    (\"SQL\", \"SQL query writing and optimization.\", category_id_map[\"Database Technologies\"]),\n",
    "    (\"NoSQL\", \"NoSQL database management.\", category_id_map[\"Database Technologies\"]),\n",
    "    (\"DB Admin\", \"Database administration.\", category_id_map[\"Database Technologies\"]),\n",
    "    (\"DB Design\", \"Database design and normalization.\", category_id_map[\"Database Technologies\"]),\n",
    "\n",
    "    # Business Intelligence\n",
    "    (\"Power BI\", \"Business intelligence with Power BI.\", category_id_map[\"Business Intelligence\"]),\n",
    "    (\"Tableau\", \"Data visualization with Tableau.\", category_id_map[\"Business Intelligence\"]),\n",
    "    (\"Apache Superset\", \"Business intelligence with Apache Superset.\", category_id_map[\"Business Intelligence\"]),\n",
    "    (\"BI Tools\", \"Using various business intelligence tools.\", category_id_map[\"Business Intelligence\"]),\n",
    "\n",
    "    # User Interface Design\n",
    "    (\"UX/UI Design\", \"User experience and user interface design.\", category_id_map[\"User Interface Design\"]),\n",
    "    (\"Web Design\", \"Designing responsive web layouts.\", category_id_map[\"User Interface Design\"]),\n",
    "    (\"Graphic Design\", \"Graphic design for web and print.\", category_id_map[\"User Interface Design\"]),\n",
    "    (\"Interaction Design\", \"Designing interactive user interfaces.\", category_id_map[\"User Interface Design\"]),\n",
    "\n",
    "    # Mobile Development\n",
    "    (\"Flutter\", \"Mobile app development with Flutter.\", category_id_map[\"Mobile Development\"]),\n",
    "    (\"React Native\", \"Building mobile apps with React Native.\", category_id_map[\"Mobile Development\"]),\n",
    "    (\"iOS\", \"Developing apps for iOS.\", category_id_map[\"Mobile Development\"]),\n",
    "    (\"Android\", \"Developing apps for Android.\", category_id_map[\"Mobile Development\"]),\n",
    "\n",
    "    # Web Scraping\n",
    "    (\"Selenium\", \"Web scraping with Selenium.\", category_id_map[\"Web Scraping\"]),\n",
    "    (\"Puppeteer\", \"Automated browser control with Puppeteer.\", category_id_map[\"Web Scraping\"]),\n",
    "    (\"Web Crawl\", \"Crawling websites for data extraction.\", category_id_map[\"Web Scraping\"]),\n",
    "    (\"Data Scraping\", \"Extracting data from web sources.\", category_id_map[\"Web Scraping\"]),\n",
    "\n",
    "    # Scripting Languages\n",
    "    (\"Python\", \"Scripting with Python.\", category_id_map[\"Scripting Languages\"]),\n",
    "    (\"Bash\", \"Shell scripting with Bash.\", category_id_map[\"Scripting Languages\"]),\n",
    "    (\"Ruby\", \"Scripting with Ruby.\", category_id_map[\"Scripting Languages\"]),\n",
    "    (\"PowerShell\", \"Automation with PowerShell.\", category_id_map[\"Scripting Languages\"]),\n",
    "\n",
    "    # ELT / ETL Technologies\n",
    "    (\"DBT\", \"Data transformation with DBT.\", category_id_map[\"ELT / ETL Technologies\"]),\n",
    "    (\"Alteryx\", \"Data processing with Alteryx.\", category_id_map[\"ELT / ETL Technologies\"]),\n",
    "    (\"Azure Synapse\", \"Data warehousing with Azure Synapse.\", category_id_map[\"ELT / ETL Technologies\"]),\n",
    "    (\"Databricks\", \"Big data processing with Databricks.\", category_id_map[\"ELT / ETL Technologies\"])\n",
    "]\n",
    "\n",
    "\n",
    "# Generate Skill entries with Faker-generated IDs\n",
    "skills = [\n",
    "    {\n",
    "        \"id\": faker.uuid4(),\n",
    "        \"name\": name,\n",
    "        \"description\": description,\n",
    "        \"org_id\": org_id,\n",
    "        \"skill_category_id\": skill_category_id\n",
    "    }\n",
    "    for name, description, skill_category_id in skills_info\n",
    "]\n",
    "\n",
    "# Convert to JSON string for output\n",
    "skills_json = json.dumps(skills, indent=2)\n",
    "\n",
    "# Writing the skills data to a JSON file\n",
    "skills_file_path = 'data/skills.json'\n",
    "with open(skills_file_path, 'w') as file:\n",
    "    file.write(skills_json)\n",
    "\n",
    "skills_file_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Inserting Roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static organization ID\n",
    "org_id = '8fd51c1d-32f9-48e3-a473-cf57f29bea05'\n",
    "\n",
    "# Define roles in a hierarchy\n",
    "roles_info = [\n",
    "    {\"name\": \"CEO\", \"description\": \"Chief Executive Officer\", \"parent\": None, \"rank\": 1},\n",
    "    {\"name\": \"CTO\", \"description\": \"Chief Technology Officer\", \"parent\": \"CEO\", \"rank\": 2},\n",
    "    {\"name\": \"VP of Engineering\", \"description\": \"Vice President of Engineering\", \"parent\": \"CTO\", \"rank\": 3},\n",
    "    {\"name\": \"Engineering Manager\", \"description\": \"Manages engineering teams\", \"parent\": \"VP of Engineering\", \"rank\": 4},\n",
    "    {\"name\": \"Senior Software Engineer\", \"description\": \"Develops high-level software solutions\", \"parent\": \"Engineering Manager\", \"rank\": 5},\n",
    "    {\"name\": \"Software Engineer\", \"description\": \"Develops software applications\", \"parent\": \"Engineering Manager\", \"rank\": 6},\n",
    "    {\"name\": \"Junior Software Engineer\", \"description\": \"Assists in software development\", \"parent\": \"Software Engineer\", \"rank\": 7}\n",
    "]\n",
    "\n",
    "# Generate Role entries with IDs and hierarchy\n",
    "roles = []\n",
    "role_ids = {}\n",
    "\n",
    "for role_info in roles_info:\n",
    "    role_id = faker.uuid4()\n",
    "    role_ids[role_info[\"name\"]] = role_id\n",
    "\n",
    "    parent_id = role_ids.get(role_info[\"parent\"]) if role_info[\"parent\"] else None\n",
    "\n",
    "    role = {\n",
    "        \"id\": role_id,\n",
    "        \"name\": role_info[\"name\"],\n",
    "        \"description\": role_info[\"description\"],\n",
    "        \"org_id\": org_id,\n",
    "        \"parent_id\": parent_id,\n",
    "        \"rank\": role_info[\"rank\"]\n",
    "    }\n",
    "    roles.append(role)\n",
    "\n",
    "# Convert to JSON string\n",
    "roles_json = json.dumps(roles, indent=2)\n",
    "\n",
    "# Displaying part of the JSON for brevity\n",
    "print(roles_json[:1000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
